you didnt give directory inputs, using test file
[0.01, 0.06, 0.11, 0.16]
/apps/spark-2.2.0/python/lib/pyspark.zip/pyspark/mllib/regression.py:281: UserWarning: Deprecated in 2.0.0. Use ml.regression.LinearRegression.
mean squar error = [9.3914702431627912, 9.2300983622001098, 10.925396786219626, 37.840505091819622]
  File "/home/sarmstr5/hw3/src/sgd_lr.py", line 84
    .addGrid(lr.stepSize=[x / float(100) for x in range(1, 20, 5]))
                                                                ^
SyntaxError: invalid syntax
  File "/home/sarmstr5/hw3/src/sgd_lr.py", line 91
    val predictions = model.transform(test)
                  ^
SyntaxError: invalid syntax
  File "/home/sarmstr5/hw3/src/sgd_lr.py", line 92
    val predictions = model.transform(test)
                  ^
SyntaxError: invalid syntax
  File "/home/sarmstr5/hw3/src/sgd_lr.py", line 92
    val predictions = lr.transform(test)
                  ^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "/home/sarmstr5/hw3/src/sgd_lr.py", line 215, in <module>
    main()
  File "/home/sarmstr5/hw3/src/sgd_lr.py", line 150, in main
    header = data.first()
  File "/apps/spark-2.2.0/python/lib/pyspark.zip/pyspark/rdd.py", line 1361, in first
  File "/apps/spark-2.2.0/python/lib/pyspark.zip/pyspark/rdd.py", line 1313, in take
  File "/apps/spark-2.2.0/python/lib/pyspark.zip/pyspark/rdd.py", line 385, in getNumPartitions
  File "/apps/spark-2.2.0/python/lib/py4j-0.10.4-src.zip/py4j/java_gateway.py", line 1133, in __call__
  File "/apps/spark-2.2.0/python/lib/py4j-0.10.4-src.zip/py4j/protocol.py", line 319, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o21.partitions.
: org.apache.hadoop.mapred.InvalidInputException: Input path does not exist: hdfs://mri-head:8020/user/sarmstr5/data/processed_train.csv
	at org.apache.hadoop.mapred.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:285)
	at org.apache.hadoop.mapred.FileInputFormat.listStatus(FileInputFormat.java:228)
	at org.apache.hadoop.mapred.FileInputFormat.getSplits(FileInputFormat.java:313)
	at org.apache.spark.rdd.HadoopRDD.getPartitions(HadoopRDD.scala:194)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:250)
	at org.apache.spark.rdd.MapPartitionsRDD.getPartitions(MapPartitionsRDD.scala:35)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:252)
	at org.apache.spark.rdd.RDD$$anonfun$partitions$2.apply(RDD.scala:250)
	at scala.Option.getOrElse(Option.scala:121)
	at org.apache.spark.rdd.RDD.partitions(RDD.scala:250)
	at org.apache.spark.api.java.JavaRDDLike$class.partitions(JavaRDDLike.scala:61)
	at org.apache.spark.api.java.AbstractJavaRDDLike.partitions(JavaRDDLike.scala:45)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:214)
	at java.lang.Thread.run(Thread.java:748)

